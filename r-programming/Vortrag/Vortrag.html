<!DOCTYPE html>
<html>
<head>
  <title>Live-Demo in R</title>
  <meta charset="utf-8">
  <meta name="description" content="Live-Demo in R">
  <meta name="author" content="">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->  <link rel=stylesheet href="./assets/css/ribbons.css"></link>

  
  <!-- Grab CDN jQuery, fall back to local if offline -->
  <script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
  <script>window.jQuery || document.write('<script src="libraries/widgets/quiz/js/jquery.js"><\/script>')</script> 
  <script data-main="libraries/frameworks/io2012/js/slides" 
    src="libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
  

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
        <slide class="title-slide segue nobackground">
  <hgroup class="auto-fadein">
    <h1>Live-Demo in R</h1>
    <h2>Workflow of a typical data analysis</h2>
    <p><br/></p>
  </hgroup>
  <article></article>  
</slide>
    

    <!-- SLIDES -->
    <slide class="" id="slide-1" style="background:;">
  <hgroup>
    <h2>A live demo</h2>
  </hgroup>
  <article data-timings="">
    <ol>
<li><p>General note on data graphics in R</p></li>
<li><p>We demonstrate the typical workflow of an in-depth analysis</p>

<ul>
<li>Data cleaning</li>
<li>Exploratory analysis</li>
<li>Statistical methods</li>
<li>Model evaluation &amp; feature selection</li>
</ul></li>
<li><p>Step-by-step demonstration</p></li>
</ol>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Analysis goals</h2>
  </hgroup>
  <article data-timings="">
    <ol>
<li><p><b> Analyze decisions on credit approvals </b> </p>

<ul>
<li>From the free dataset repository of the University of California <br /> (<a href="https://archive.ics.uci.edu/ml/datasets.html">https://archive.ics.uci.edu/ml/datasets.html</a>)</li>
<li>Data about credit card applications</li>
<li>Contains a good mix of continuous and nominal attributes, <br /> including a few missing values</li>
</ul></li>
<li><p><b> Analytical questions</b></p>

<ul>
<li>What are driving attributes behind approvals?</li>
<li>Can we predict approvals?</li>
<li>Are there clear rules?</li>
</ul></li>
</ol>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Methods</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li><p>Understanding the data via queries, aggregations and visualizations</p></li>
<li><p>See if there is a clustering of acceptance/denial events</p></li>
<li><p>Predicting the outcome of the credit card application via classification/regression</p></li>
<li><p>Model evaluation</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Introduction</h2>
  </hgroup>
  <article data-timings="">
    <p><br/>
<br/>
<br/>
<br/></p>

<h2>Basic concepts of data graphics in R</h2>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>An overview of data graphics in R</h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>There are 3 main graphics systems in R

<ul>
<li>built-in functionality (examples: plot(), hist(), etc.)</li>
<li><code>lattice</code> package (e.g. scatterplot matrices)</li>
<li><code>ggplot2</code> (implements &#39;The Grammar of Graphics&#39; [Wilkinson, 2005])</li>
</ul></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Creating a data toy example (1/2)</h2>
  </hgroup>
  <article data-timings="">
    <h4>Examplify different plotting options of R with a little toy dataset </h4>

<ul>
<li>The following code generates our toy data</li>
<li>We will skip the code for a moment to get the intuition from a few appropriate plots</li>
<li>Data: Relationships between 3 price classes, product quality and customer satisfaction</li>
</ul>

<pre><code class="r"># Create a scaling funtion that returns values between 0 and 100(%)
scale.fun &lt;- function(vals) {return(abs( vals / max(vals) * 100 ))}
# Assume three different quality levels
quality.levels &lt;- factor(c(1,2,3), labels=c(&quot;low&quot;, &quot;mid&quot;, &quot;hi&quot;))
# Create a vector with 100 entries for each level
qualities &lt;- rep(quality.levels, 100)
table(qualities)
</code></pre>

<pre><code>## qualities
## low mid  hi 
## 100 100 100
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Creating a data toy example (2/2)</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Model relationship between price &amp; customer satisfaction for different quality levels
dat &lt;- data.frame(satisfaction=NA, price=NA, quality=qualities)

dat$price[dat$quality==&quot;low&quot;] &lt;- 50:149
dat$price[dat$quality==&quot;mid&quot;] &lt;- 150:249
dat$price[dat$quality==&quot;hi&quot;] &lt;- 250:349

dat$satisfaction[dat$quality==&quot;low&quot;] &lt;- scale.fun(0.1 * 1:100 + rnorm(100))
dat$satisfaction[dat$quality==&quot;mid&quot;] &lt;- scale.fun(0.75 * 1:100 + rnorm(100))
dat$satisfaction[dat$quality==&quot;hi&quot;] &lt;- scale.fun(runif(100))
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Example of a basic plot</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Create a histogram, suppress default label for x-axis
hist(dat$satisfaction, main=&quot;Distribution of people&#39;s satisfaction&quot;, xlab=&quot;&quot;)
# One can add things to the opened plot
title(xlab = &quot;satisfaction level&quot;)
</code></pre>

<p><img src="assets/fig/unnamed-chunk-3-1.png" alt="plot of chunk unnamed-chunk-3"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>A simple <code>lattice</code> example</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">require(lattice)
# Create a scatterplot for each quality level
xyplot(satisfaction ~ price | quality, data = dat)
</code></pre>

<p><img src="assets/fig/unnamed-chunk-4-1.png" alt="plot of chunk unnamed-chunk-4"></p>

<p>Note that we can see now differing correlations between the variables.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>A simple <code>ggplot2</code> example</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">require(ggplot2)
# Plot price vs. satisfaction in a colored scatterplot (Note: British spelling!)
ggplot(dat, aes(x=price, y=satisfaction, colour=quality)) + geom_point() 
</code></pre>

<p><img src="assets/fig/unnamed-chunk-5-1.png" alt="plot of chunk unnamed-chunk-5"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Other <code>ggplot2</code> examples (1/2)</h2>
  </hgroup>
  <article data-timings="">
    <p>The concept of the grammar of graphs allows for easy adjustments of the visualization</p>

<pre><code class="r"># Now a boxplot of the data (with a slight change of the command)
ggplot(dat, aes(x=price, y=satisfaction, colour=quality)) + geom_boxplot() 
</code></pre>

<p><img src="assets/fig/unnamed-chunk-6-1.png" alt="plot of chunk unnamed-chunk-6"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Other <code>ggplot2</code> examples (2/2)</h2>
  </hgroup>
  <article data-timings="">
    <p>E.g. overlaying of several plots. For more information please have a look at:<br/>
<a href="https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf">https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf</a></p>

<pre><code class="r"># Now a boxplot of the data (with a slight change of the command)
ggplot(dat, aes(x=price, y=satisfaction, colour=quality)) + geom_point() + 
       geom_density2d(alpha=0.3)
</code></pre>

<p><img src="assets/fig/unnamed-chunk-7-1.png" alt="plot of chunk unnamed-chunk-7"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Note on <code>ggplot2</code></h2>
  </hgroup>
  <article data-timings="">
    <ul>
<li>The <em>grammar of graphics</em> formalizes a mapping of data characteristics to graphics, including:

<ul>
<li><em>geoms</em>: Types of graphs</li>
<li><em>aesthetics</em>: Dimensions of the graphs (&quot;x-axis&quot;, &quot;y-axis&quot;, &quot;color&quot;)</li>
<li class='..'>and various other items</li>
</ul></li>
</ul>

<pre><code class="r">g &lt;- ggplot(dat, aes(x=price, y=satisfaction, colour=quality)) + geom_point() 
</code></pre>

<ul>
<li>The plus-sign is used to compose graphs</li>
<li>There is also a convenience function <code>qplot</code></li>
<li>For furter information, have a look into the <em>R Graphics Cookbook</em></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Data Analysis - Part I</h2>
  </hgroup>
  <article data-timings="">
    <p><br/>
<br/>
<br/>
<br/></p>

<h2>Data cleaning</h2>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Loading the data</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Read in the credit data from a CSV-file
raw.data &lt;- read.csv(&quot;credit.csv&quot;, header=T, sep=&quot;,&quot;, stringsAsFactors=F)
</code></pre>

<p><br/>
The variable <code>raw.data</code> is of type <i>data.frame</i>.</p>

<pre><code class="r"># How many rows and columns? (&quot;dimensions&quot; of the data frame)
dim(raw.data)
</code></pre>

<pre><code>## [1] 690  16
</code></pre>

<pre><code class="r">colnames(raw.data) # column names
</code></pre>

<pre><code>##  [1] &quot;A1&quot;    &quot;A2&quot;    &quot;A3&quot;    &quot;A4&quot;    &quot;A5&quot;    &quot;A6&quot;    &quot;A7&quot;    &quot;A8&quot;   
##  [9] &quot;A9&quot;    &quot;A10&quot;   &quot;A11&quot;   &quot;A12&quot;   &quot;A13&quot;   &quot;A14&quot;   &quot;A15&quot;   &quot;Class&quot;
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>An initial inspection of the data</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># The str-function provides a quick overview
str(raw.data)
</code></pre>

<pre><code>## &#39;data.frame&#39;:    690 obs. of  16 variables:
##  $ A1   : chr  &quot;b&quot; &quot;a&quot; &quot;a&quot; &quot;b&quot; ...
##  $ A2   : num  30.8 58.7 24.5 27.8 20.2 ...
##  $ A3   : num  0 4.46 0.5 1.54 5.62 ...
##  $ A4   : chr  &quot;u&quot; &quot;u&quot; &quot;u&quot; &quot;u&quot; ...
##  $ A5   : chr  &quot;g&quot; &quot;g&quot; &quot;g&quot; &quot;g&quot; ...
##  $ A6   : chr  &quot;w&quot; &quot;q&quot; &quot;q&quot; &quot;w&quot; ...
##  $ A7   : chr  &quot;v&quot; &quot;h&quot; &quot;h&quot; &quot;v&quot; ...
##  $ A8   : num  1.25 3.04 1.5 3.75 1.71 ...
##  $ A9   : chr  &quot;t&quot; &quot;t&quot; &quot;t&quot; &quot;t&quot; ...
##  $ A10  : chr  &quot;t&quot; &quot;t&quot; &quot;f&quot; &quot;t&quot; ...
##   [list output truncated]
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Treatment of missing values (1/2)</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">dim(raw.data)
</code></pre>

<pre><code>## [1] 690  16
</code></pre>

<pre><code class="r"># Check for missing values  
any(is.na(raw.data))
</code></pre>

<pre><code>## [1] TRUE
</code></pre>

<pre><code class="r"># Account for empty strings
raw.data[raw.data == &quot;&quot;] &lt;- NA
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Treatment of missing values (2/2)</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Drop rows with NaN values
na.raw.inds &lt;- which(apply(is.na(raw.data), 1, any))
length(na.raw.inds)
</code></pre>

<pre><code>## [1] 37
</code></pre>

<pre><code class="r">raw.data &lt;- raw.data[-c(na.raw.inds),]
dim(raw.data)
</code></pre>

<pre><code>## [1] 653  16
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Inspecting a subset of the data</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Show a sample from the data
raw.data[c(1,5,8,353,601),]
</code></pre>

<pre><code>##     A1    A2     A3 A4 A5 A6 A7   A8 A9 A10 A11 A12 A13 A14  A15 Class
## 1    b 30.83  0.000  u  g  w  v 1.25  t   t   1   f   g 202    0     +
## 5    b 20.17  5.625  u  g  w  v 1.71  t   f   0   f   s 120    0     +
## 8    a 22.92 11.585  u  g cc  v 0.04  t   f   0   f   g  80 1349     +
## 370  b 21.42  0.750  y  p  r  n 0.75  f   f   0   t   g 132    2     -
## 636  b 18.17  2.460  u  g  c  n 0.96  f   t   2   t   g 160  587     -
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Replacements of symbolic true/false values (1/2)</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># We already know that the Class-column contains + and - signs
unique(raw.data$Class)
</code></pre>

<pre><code>## [1] &quot;+&quot; &quot;-&quot;
</code></pre>

<pre><code class="r"># However, what else?
head(raw.data, n=1)
</code></pre>

<pre><code>##   A1    A2 A3 A4 A5 A6 A7   A8 A9 A10 A11 A12 A13 A14 A15 Class
## 1  b 30.83  0  u  g  w  v 1.25  t   t   1   f   g 202   0     +
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Replacements of symbolic true/false values (2/2)</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Replace +/- values with 1/0
raw.data[raw.data$Class == &quot;+&quot;, &quot;Class&quot;] &lt;- 1.0 
raw.data[raw.data$Class == &quot;-&quot;, &quot;Class&quot;] &lt;- 0.0
</code></pre>

<p><br/>
Conveniently, none of the categorical attributes contains the strings &#39;t&#39; of &#39;f&#39;, <br/>
hence, we can easily substitute ...</p>

<pre><code class="r"># Replace t/f values with 1/0
raw.data[raw.data == &quot;t&quot;] &lt;- 1.0
raw.data[raw.data == &quot;f&quot;] &lt;- 0.0
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Creating dummies for categorical variables (1/3)</h2>
  </hgroup>
  <article data-timings="">
    <p>Separate the sets of categorical and numerical variables</p>

<pre><code class="r"># (Already) numeric columns
to.keep &lt;- c(&quot;Class&quot;, &quot;A2&quot;, &quot;A3&quot;, &quot;A8&quot;, &quot;A9&quot;, &quot;A10&quot;, &quot;A11&quot;,&quot;A12&quot;,&quot;A14&quot;,&quot;A15&quot;)
# Categorical columns
to.split &lt;- c(&quot;A1&quot;, &quot;A4&quot;, &quot;A5&quot;, &quot;A6&quot;, &quot;A7&quot;, &quot;A13&quot;)
</code></pre>

<pre><code class="r"># Separate numeric from categorical data
numeric.data &lt;- raw.data[, to.keep]
dim(numeric.data)
</code></pre>

<pre><code>## [1] 653  10
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Creating dummies for categorical variables (2/3)</h2>
  </hgroup>
  <article data-timings="">
    <p>Introduce new columns with 0/1 values for categorical values</p>

<pre><code class="r">ext.raw.data &lt;- raw.data[,to.keep] # create a copy of the data frame

for (j in to.split) { # for each categorical variable

  fac &lt;- as.factor(raw.data[,j]) # represent column as a factor
  for (categ in levels(fac)) { # handle each category (&#39;level&#39;) 

    tmp.vec &lt;- fac == categ # creates vector of true/false values
    tmp.vec &lt;- as.numeric(tmp.vec) # true =&gt; 1 # false =&gt; 0
    ext.raw.data &lt;- cbind(ext.raw.data, tmp.vec) # append new column to data frame
    colnames(ext.raw.data)[ncol(ext.raw.data)] &lt;-
      sprintf(&quot;%s(%s)&quot;, j, categ) # create useful column name
  }
}
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Creating dummies for categorical variables (3/3)</h2>
  </hgroup>
  <article data-timings="">
    <p>Compare the dimensions of the data frame before and afterwards</p>

<pre><code class="r">print(paste(dim(raw.data), dim(ext.raw.data), sep= &quot; vs. &quot;))
</code></pre>

<pre><code>## [1] &quot;653 vs. 653&quot; &quot;16 vs. 44&quot;
</code></pre>

<p><br/>
Show example of new columns:</p>

<pre><code class="r">lc.ind &lt;- ncol(ext.raw.data)
str(ext.raw.data[, (lc.ind -2):lc.ind])
</code></pre>

<pre><code>## &#39;data.frame&#39;:    653 obs. of  3 variables:
##  $ A13(g): num  1 1 1 1 0 1 1 1 1 1 ...
##  $ A13(p): num  0 0 0 0 0 0 0 0 0 0 ...
##  $ A13(s): num  0 0 0 0 1 0 0 0 0 0 ...
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Export data to csv for inspection in an external editor</h2>
  </hgroup>
  <article data-timings="">
    <p>Export to csv:</p>

<pre><code class="r">write.table(ext.raw.data, &quot;binarized_credit_data.csv&quot;, col.names = T, 
            row.names=F, quote=F, sep=&quot;,&quot;)
</code></pre>

<p><br/>
Reading it back in:</p>

<pre><code class="r">ext.raw.data &lt;- read.csv(ext.raw.data, &quot;binarized_credit_data.csv&quot;, header=T,
                         stringsAsFactors = F, sep=&quot;,&quot;)
</code></pre>

<p><br/>
Finally, we update the name of the data frame to stay consistent</p>

<pre><code class="r">data &lt;- ext.raw.data
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Data Analysis - Part II</h2>
  </hgroup>
  <article data-timings="">
    <p><br/>
<br/>
<br/>
<br/></p>

<h2>Exploratory analysis</h2>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Count non-zero entries (1/2)</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Check if all columns are numeric
all(sapply(data, is.numeric))
</code></pre>

<pre><code>## [1] FALSE
</code></pre>

<pre><code class="r"># Need to convert each column of the matrix
data &lt;- as.data.frame(apply(data, 2, as.numeric))
all(sapply(data, is.numeric))
</code></pre>

<pre><code>## [1] TRUE
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Count non-zero entries (2/2)</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">table(data[,&quot;Class&quot;])
</code></pre>

<pre><code>## 
##   0   1 
## 357 296
</code></pre>

<pre><code class="r"># Count the non-zero entries of each attribute for each class
agg &lt;- aggregate(subset(data, select = -Class), by=list(Class = data[,&quot;Class&quot;]),
          function(x) {length(x[x &gt;0])})
agg[,c(1:10)]
</code></pre>

<pre><code>##   Class  A2  A3  A8  A9 A10 A11 A12 A14 A15
## 1     0 357 349 311  71  84  84 157 309 190
## 2     1 296 291 282 278 203 203 145 216 188
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Determining discriminative attributes (1/3)</h2>
  </hgroup>
  <article data-timings="">
    <p>We want to mark interesting attributes with high presence and strong discriminativity. This section also demonstrates the print()-function of R.</p>

<pre><code class="r">agg &lt;- subset(agg, select=-Class)
ratios &lt;- sapply(agg, function(x) {x[2] / x[1]})
nonzeros &lt;- colSums(agg)
inds.decreasing &lt;- order(nonzeros, decreasing=T)

# Prepare a print-out ...
print(sprintf(&quot;% -8s % -8s (% -s)&quot;, &quot;Attribute&quot;, &quot;Count&quot;, &quot;Ratio&quot;))
print(&quot;--------------------------&quot;)
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Determining discriminative attributes (2/3)</h2>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Do the print-out ...
for (i in inds.decreasing[1:15]) { # print out top 15 elements
  count &lt;- nonzeros[i]
  ratio &lt;- ratios[i]
  if (count &gt; 10) {
    if (ratio &gt; 2 || ratio &lt; 0.5) {
      print(sprintf(&quot;% -8s % -8s  (%.2f)  &lt;-- discriminates the classes well)&quot;, 
                    names(ratios)[i], count, ratio))
    } else {
      print(sprintf(&quot;% -8s % -8s  (%.2f)&quot;, names(ratios)[i], count, ratio))
    }
  }
}
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Determining discriminative attributes (3/3)</h2>
  </hgroup>
  <article data-timings="">
    <pre><code>## [1] &quot;Attribute Count    (Ratio)&quot;
## [1] &quot;--------------------------&quot;
## [1] &quot;A2       653       (0.83)&quot;
## [1] &quot;A3       640       (0.83)&quot;
## [1] &quot;A13(g)   598       (0.88)&quot;
## [1] &quot;A8       593       (0.91)&quot;
## [1] &quot;A14      525       (0.70)&quot;
## [1] &quot;A4(u)    499       (1.00)&quot;
## [1] &quot;A5(g)    499       (1.00)&quot;
## [1] &quot;A1(b)    450       (0.81)&quot;
## [1] &quot;A7(v)    381       (0.75)&quot;
## [1] &quot;A15      378       (0.99)&quot;
## [1] &quot;A9       349       (3.92)  &lt;-- discriminates the classes well)&quot;
## [1] &quot;A12      302       (0.92)&quot;
## [1] &quot;A10      287       (2.42)  &lt;-- discriminates the classes well)&quot;
## [1] &quot;A11      287       (2.42)  &lt;-- discriminates the classes well)&quot;
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Selecting discriminative attributes by correlations</h2>
  </hgroup>
  <article data-timings="">
    <p>This is an alternative approach for determining single descriminative attributes. We rank attributes by their pairwise Pearson&#39;s correlations with the class labels.</p>

<pre><code class="r"># Compute Pearson&#39;s correlation between attributes and the class labels
test &lt;- cor(subset(data, select=-Class), as.numeric(data[,&quot;Class&quot;]))
sort(test, decreasing = T)[1:10]
</code></pre>

<pre><code>##  [1] 0.7388289 0.4518657 0.4060516 0.3327282 0.2070860 0.1881173 0.1844048
##  [8] 0.1802520 0.1727660 0.1652691
</code></pre>

<pre><code class="r">top5 &lt;- rownames(test)[order(test, decreasing = T)][1:5]
top5
</code></pre>

<pre><code>## [1] &quot;A9&quot;  &quot;A10&quot; &quot;A11&quot; &quot;A8&quot;  &quot;A3&quot;
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Visualizing with a scatterplot matrix (1/4)</h2>
  </hgroup>
  <article data-timings="">
    <p>First, we need to select all non-binary columns from the data frame</p>

<pre><code class="r">selection &lt;- which(apply(data, 2, function(x) {!(all(is.element(x, c(0,1))))}))
</code></pre>

<p><br/>
<b>Option 1:</b> Using the built-in functionality</code></p>

<pre><code class="r"># Builtin-function &#39;pairs&#39;
pairs(data[,selection], main = &quot;Scatterplots for credit attributes&quot;, 
      pch = 21, bg = c(&quot;red&quot;, &quot;green3&quot;)[data$Class + 1])

# Note: See plot on next slide
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Visualizing with a scatterplot matrix (2/4)</h2>
  </hgroup>
  <article data-timings="">
    <p><img src="assets/fig/unnamed-chunk-35-1.png" alt="plot of chunk unnamed-chunk-35"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Visualizing with a scatterplot matrix (3/4)</h2>
  </hgroup>
  <article data-timings="">
    <p><b>Option 2:</b> Using functionality from <code>ggplot2</code></p>

<pre><code class="r"># To beautify the labeling of the plots, we should convert the class into a factor
data[,&quot;Class&quot;] &lt;- factor(data[,&quot;Class&quot;], levels = c(&quot;0&quot;,&quot;1&quot;), 
                         labels=c(&quot;denial&quot;, &quot;approval&quot;))

multi_colored_kde &lt;- function(data, mapping, ...){
  ggplot(data = data, mapping=mapping) +
    geom_density(mapping = aes_string(color=&quot;Class&quot;), fill=NA)
}

ggpairs(data, columns=selection, title= &quot;Scatterplot matrix&quot;, 
        mapping=ggplot2::aes_string(color=&quot;Class&quot;),
        upper=&quot;blank&quot;,
        diag  = list(continuous=multi_colored_kde),
        lower = list(continuous=wrap(&quot;points&quot;, alpha=0.2)),
        axisLabels= &quot;none&quot;) # Note: See plot on next slide
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Visualizing with a scatterplot matrix (4/4)</h2>
  </hgroup>
  <article data-timings="">
    <p><img src="assets/fig/unnamed-chunk-38-1.png" alt="plot of chunk unnamed-chunk-38"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Heatmap visualization of pairwise correlations (1/3)</h2>
  </hgroup>
  <article data-timings="">
    <p>A heatmap is a colored matrix, where the color intensity of cells represents the strengths of pairwise relationships.</p>

<pre><code class="r">require(d3heatmap, quietly = T) # load one of the packages for heatmaps

# To compute pairwise correlations, attributes need to be numeric
tmp &lt;- as.matrix(sapply(subset(data, select = -Class), as.numeric))
tmp &lt;- cbind(tmp, as.integer(as.character(data$Class) == &quot;approval&quot;))
colnames(tmp)[ncol(tmp)] &lt;- &quot;Class&quot;
# Compute a matrix of pairwise correlations
tmp.cor &lt;- cor(tmp)
any(is.na(tmp.cor)) # columns with very low variance may introduce NAs
tmp.cor[is.na(tmp.cor)] &lt;- 0

d3heatmap(abs(tmp.cor),color = &quot;Reds&quot;,dendrogram = &quot;none&quot;)
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Heatmap visualization of pairwise correlations (2/3)</h2>
  </hgroup>
  <article data-timings="">
    <p><img src="./d3heatmap_plot.png" style="width:850px" /></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Heatmap visualization of pairwise correlations (3/3)</h2>
  </hgroup>
  <article data-timings="">
    <p><img src="./d3heatmap_plot_highlighted.png" style="width:850px" /></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Hint: Working with re-usable code snippets</h2>
  </hgroup>
  <article data-timings="">
    <p>You can outsource codeblocks to make them re-usable<br/>
the comand <code>source()</code> reads in and executes an R-script</p>

<pre><code class="r">source(&#39;read_in_credit_data.R&#39;)
source(&#39;preprocess_credit_data.R&#39;)
source(&#39;scatter_plot_matrix.R&#39;)
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Data Analysis - Part III</h2>
  </hgroup>
  <article data-timings="">
    <p><br/>
<br/>
<br/>
<br/></p>

<h2>Statistical methods</h2>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Pre-filtering of attributes</h2>
  </hgroup>
  <article data-timings="">
    <p>Depending on the methods, some of the following steps are necessary (e.g. for principal component analysis)</p>

<pre><code class="r"># Separate the class from the rest of the data
classes &lt;- data[,&quot;Class&quot;]
data &lt;- subset(data, select=-Class)

# Remove columns with little variation
require(caret)
data &lt;- data[,-c(nearZeroVar(data))]

# Center and scale columns (necessary for some ML-methods)
data.orig &lt;- data
data &lt;- scale(data)
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Compute a PCA</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">pca &lt;- prcomp(data)
pca4plot &lt;- as.data.frame(pca$x)
pca4plot[,&quot;Class&quot;] &lt;- classes
ggplot(pca4plot, aes(x=PC1, y=PC2, colour=Class)) + geom_point()
</code></pre>

<p><img src="assets/fig/unnamed-chunk-42-1.png" alt="plot of chunk unnamed-chunk-42"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Scatterplot matrix of a PCA (1/2)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">ggpairs(pca4plot, columns= c(1,2,3,4), color=&quot;Class&quot;, title= &quot;Scatterplot matrix&quot;, 
        mapping=ggplot2::aes_string(color=&quot;Class&quot;),
        upper=&quot;blank&quot;,
        diag  = list(continuous=multi_colored_kde),
        lower = list(continuous=wrap(&quot;points&quot;, alpha=0.2)),
        axisLabels= &quot;none&quot;)

# Note: See plot on next slide
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Scatterplot matrix of a PCA (2/2)</h1>
  </hgroup>
  <article data-timings="">
    <p><img src="assets/fig/unnamed-chunk-44-1.png" alt="plot of chunk unnamed-chunk-44"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Computing kmeans-clusters (1/4)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Since k-means starts with a randomized initialization, we fix a random seed
# for reproducibility of the experiments
set.seed(10) 

clustIDs &lt;- kmeans(data, 2)$cluster
pca4plot[,&quot;Cluster&quot;] &lt;- as.factor(clustIDs)
ggplot(pca4plot, aes(x=PC1, y=PC2, colour=Class, shape=Cluster)) 
       + geom_point(size=4, alpha=0.75)

clustIDs &lt;- kmeans(data, 3)$cluster
pca4plot[,&quot;Cluster&quot;] &lt;- as.factor(clustIDs)
ggplot(pca4plot, aes(x=PC1, y=PC2, colour=Class, shape=Cluster))
       + geom_point(size=4, alpha=0.75)

# Note: See plots on next slides
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Computing kmeans-clusters (2/4)</h1>
  </hgroup>
  <article data-timings="">
    <p>Assuming 2 cluster centers</p>

<p><img src="assets/fig/unnamed-chunk-46-1.png" alt="plot of chunk unnamed-chunk-46"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Computing kmeans-clusters (3/4)</h1>
  </hgroup>
  <article data-timings="">
    <p>Assuming 3 cluster centers</p>

<p><img src="assets/fig/unnamed-chunk-47-1.png" alt="plot of chunk unnamed-chunk-47"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Computing kmeans-clusters (4/4)</h1>
  </hgroup>
  <article data-timings="">
    <p>Use another form of visualizing</p>

<pre><code class="r">library(cluster)
clusplot(data, clustIDs, color=TRUE, shade=TRUE, labels=0, lines=0, 
         main = &quot;Clusters in PCA space&quot;, xlab=&quot;PC1&quot;, ylab=&quot;PC2&quot;)
</code></pre>

<p><img src="assets/fig/unnamed-chunk-48-1.png" alt="plot of chunk unnamed-chunk-48"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Hierarchical clustering (1/2)</h1>
  </hgroup>
  <article data-timings="">
    <p>Learn a hierarchical cluster model</p>

<pre><code class="r">clusters &lt;- hclust(dist(data), method=&#39;ward.D&#39;) 
# &quot;ward.D&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;average&quot;, ...
plot(clusters)
</code></pre>

<p><img src="assets/fig/unnamed-chunk-49-1.png" alt="plot of chunk unnamed-chunk-49"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Hierarchical clustering (2/2)</h1>
  </hgroup>
  <article data-timings="">
    <p>Visualize the result for a comparison</p>

<pre><code class="r">clustIDs &lt;- cutree(clusters, k=3)
clusplot(data, clustIDs, color=TRUE, shade=TRUE, labels=0, lines=0, 
         main = &quot;Clusters in PCA space&quot;, xlab=&quot;PC1&quot;, ylab=&quot;PC2&quot;)
</code></pre>

<p><img src="assets/fig/unnamed-chunk-50-1.png" alt="plot of chunk unnamed-chunk-50"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Learning a decision tree model (1/5)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Make a split of the data into train and test set
set.seed(51)
train.sample &lt;- sample(nrow(data), floor(0.75 * 653))
str(train.sample)
</code></pre>

<pre><code>##  int [1:489] 507 131 195 641 141 541 487 263 627 73 ...
</code></pre>

<pre><code class="r">d.train &lt;- data.orig[train.sample,]
d.test &lt;- data.orig[-train.sample,]

cl.train &lt;- classes[train.sample]
cl.test &lt;- classes[-train.sample]
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Learning a decision tree model (2/5)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Check statistical properties - are they comparable?
prop.table(table(classes))
## classes
##    denial  approval 
## 0.5467075 0.4532925
prop.table(table(cl.train))
## cl.train
##    denial  approval 
## 0.5337423 0.4662577
prop.table(table(cl.test))
## cl.test
##    denial  approval 
## 0.5853659 0.4146341
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Learning a decision tree model (3/5)</h1>
  </hgroup>
  <article data-timings="">
    <p>Building the model</p>

<pre><code class="r">require(C50)
credit.model &lt;- C5.0(d.train, cl.train, control=C5.0Control(minCases=10)) 
summary(credit.model)
</code></pre>

<p><br /></p>

<p><img src="./decision_tree_output_1.png" alt="width"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Plotting the decision tree model (4/5)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">plot(credit.model)
</code></pre>

<p><br /></p>

<p><img src="./decision_tree.png" style="width: 800px;"/></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Learning a decision tree model (5/5)</h1>
  </hgroup>
  <article data-timings="">
    <p>Use the model for predictions on the test set</p>

<pre><code class="r">cred.preds &lt;- predict(credit.model, d.test)

# Make a confusion matrix for the predictions
library(gmodels)
CrossTable(cl.test, cred.preds, prop.chisq = FALSE, prop.c = FALSE, 
           prop.r =F, dnn = c(&quot;actual approval&quot;,&quot;predicted approval&quot;))
</code></pre>

<p><img src="./crosstable_output.png" alt="width"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Learning a linear model to classify the data (1/3)</h1>
  </hgroup>
  <article data-timings="">
    <p>Note that this abuses a thresholding a linear regression to classify data</p>

<pre><code class="r">tmp.train.df &lt;- as.data.frame(d.train)
tmp.train.df$Class &lt;- as.numeric(cl.train==&quot;approval&quot;)

linear.model &lt;- lm(Class ~ ., data=tmp.train.df) 
</code></pre>

<pre><code class="r"># Inspect the model
summary(linear.model)

# Note: See output on the next slide
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Learning a linear model to classify the data (2/3)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code>## 
## Call:
## lm(formula = Class ~ ., data = tmp.train.df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.89906 -0.09278  0.01710  0.16663  1.05325 
## 
## Coefficients: (4 not defined because of singularities)
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.024e+00  3.932e-01   2.605  0.00950 ** 
## A2           7.750e-04  1.471e-03   0.527  0.59857    
## A3          -4.744e-03  3.267e-03  -1.452  0.14713    
## A8           8.039e-03  5.679e-03   1.416  0.15753    
## A9           6.000e-01  3.665e-02  16.369  &lt; 2e-16 ***
## A10          1.020e-01  3.941e-02   2.587  0.00998 ** 
## A11          5.730e-03  3.720e-03   1.540  0.12417    
## A12         -1.051e-02  3.054e-02  -0.344  0.73086    
## A14         -2.977e-04  1.007e-04  -2.957  0.00327 ** 
## A15          1.282e-05  5.126e-06   2.502  0.01271 *  
## `A1(a)`      3.968e-03  3.386e-02   0.117  0.90677    
## `A1(b)`             NA         NA      NA       NA    
## `A4(u)`     -9.151e-01  3.881e-01  -2.358  0.01880 *  
## `A4(y)`     -9.884e-01  3.885e-01  -2.544  0.01128 *  
## `A5(g)`             NA         NA      NA       NA    
## `A5(p)`             NA         NA      NA       NA    
## `A6(aa)`    -5.585e-02  7.954e-02  -0.702  0.48293    
## `A6(c)`      1.901e-02  6.663e-02   0.285  0.77555    
## `A6(cc)`     6.614e-02  8.229e-02   0.804  0.42198    
## `A6(ff)`    -1.098e-01  2.005e-01  -0.548  0.58426    
## `A6(i)`     -2.014e-02  8.540e-02  -0.236  0.81370    
## `A6(k)`     -2.487e-03  7.839e-02  -0.032  0.97471    
## `A6(m)`     -3.340e-02  8.921e-02  -0.374  0.70826    
## `A6(q)`     -1.358e-02  7.383e-02  -0.184  0.85411    
## `A6(w)`      5.517e-02  7.628e-02   0.723  0.46983    
## `A6(x)`      1.602e-01  8.671e-02   1.848  0.06528 .  
## `A7(bb)`    -7.705e-02  1.054e-01  -0.731  0.46514    
## `A7(ff)`    -8.705e-02  2.042e-01  -0.426  0.67005    
## `A7(h)`      2.260e-02  8.986e-02   0.252  0.80151    
## `A7(v)`     -2.794e-02  8.518e-02  -0.328  0.74300    
## `A13(g)`     4.201e-02  6.030e-02   0.697  0.48638    
## `A13(s)`            NA         NA      NA       NA    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3204 on 461 degrees of freedom
## Multiple R-squared:  0.6111, Adjusted R-squared:  0.5883 
## F-statistic: 26.83 on 27 and 461 DF,  p-value: &lt; 2.2e-16
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Learning a linear model to classify the data (3/3)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Make predictions on new data points
linear.preds &lt;- as.numeric(predict(linear.model, d.test) &gt; 0.5)
# Inspect the results
CrossTable(cl.test, linear.preds, prop.chisq = FALSE, prop.c = FALSE, 
           prop.r =F, dnn = c(&quot;actual approval&quot;,&quot;predicted approval&quot;))
</code></pre>

<p><img src="./crosstable_lm_output.png" alt="width"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Learning with a SVM (1/3)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">library(kernlab)

dat.train.df &lt;- as.data.frame(d.train)
dat.train.df$Class &lt;- cl.train

svm.classifier &lt;- ksvm(Class ~ ., data=dat.train.df, kernel = &quot;vanilladot&quot;)
</code></pre>

<!-- Note that using the param "kpar=list()" avoids the output of the message "Setting default kernel parameters", which is otherwise unsupressable! -->

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Learning with a SVM (2/3)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">svm.classifier
</code></pre>

<pre><code>## Support Vector Machine object of class &quot;ksvm&quot; 
## 
## SV type: C-svc  (classification) 
##  parameter : cost C = 1 
## 
## Linear (vanilla) kernel function. 
## 
## Number of Support Vectors : 207 
## 
## Objective Function Value : -131.0236 
## Training error : 0.132924
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Learning with a SVM (3/3)</h1>
  </hgroup>
  <article data-timings="">
    <p>Use the model for predictions on the test set</p>

<!--

```r
library(gmodels)
```
-->

<pre><code class="r">svm.preds &lt;- predict(svm.classifier, d.test)
CrossTable(cl.test, svm.preds, prop.chisq = FALSE, prop.c = FALSE, 
           prop.r =F, dnn = c(&quot;actual approval&quot;,&quot;predicted approval&quot;))
</code></pre>

<p><img src="./Crosstable_svn.png" alt="width"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Definitions of performance measures</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Recall
recall &lt;- function(preds, targets) {
  sum(preds &amp; targets) / sum(targets) # TP / (TP + FN)
}
# Precision
precision &lt;- function(preds, targets) {
  sum(preds &amp; targets) / sum(preds) # TP / (TP + FP)
}
# Accuracy
accuracy &lt;- function(preds, targets) {
  sum(preds == targets) / length(targets) # (TP + TN) / (TP + TN + FP + FN)
}
# R-Squared
r_squared &lt;- function(preds, targets) {
  cor(preds, targets)^2 # R-Squared is equal to the squared Pearson&#39;s correlation
}
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Doing k-fold cross-validation for a SVM (1/3)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">require(kernlab, quietly=T)

tmp.train.df &lt;- as.data.frame(d.train)
tmp.train.df$Class &lt;- cl.train

set.seed(15)
# Assign a random number k in c(1:10) to each data frame row
folds &lt;- sample(rep(1:10, length=nrow(tmp.train.df)))
table(folds)
</code></pre>

<pre><code>## folds
##  1  2  3  4  5  6  7  8  9 10 
## 49 49 49 49 49 49 49 49 49 48
</code></pre>

<pre><code class="r">cv.recalls &lt;- rep(NA, 10)
cv.precisions &lt;- rep(NA, 10)
cv.accuracies &lt;- rep(NA, 10)
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Doing k-fold cross-validation for a SVM (2/3)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">for (k in 1:10) {
  # Fit model on all data samples except those having number k assigned
  fold_k.fit &lt;- ksvm(Class ~ ., data=tmp.train.df[folds!=k,], kernel = &quot;vanilladot&quot;)
  # Use model to predict labels for all data samples having number k assigned
  fold_k.preds &lt;- predict(fold_k.fit, subset(tmp.train.df[folds==k,], select=-Class))

  cv.recalls[k] &lt;- recall(fold_k.preds==&quot;approval&quot;, cl.train[folds==k]==&quot;approval&quot;)
  cv.precisions[k] &lt;- precision(fold_k.preds==&quot;approval&quot;, cl.train[folds==k]==&quot;approval&quot;)
  cv.accuracies[k] &lt;- accuracy(fold_k.preds==&quot;approval&quot;, cl.train[folds==k]==&quot;approval&quot;)
}
</code></pre>

<!-- Note that using the param "kpar=list()" avoids the output of the message "Setting default kernel parameters", which is otherwise unsupressable! -->

<pre><code class="r">summary(cv.accuracies)
</code></pre>

<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.7347  0.8571  0.8673  0.8568  0.8776  0.9184
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Doing k-fold cross-validation for a SVM (3/3)</h1>
  </hgroup>
  <article data-timings="">
    <p>Let&#39;s also plot the results of the individual folds.</p>

<pre><code class="r">plot(cv.recalls * 100, pch=19, type=&quot;b&quot;, ylim=c(0,100), main = &quot;Performance measures&quot;, xlab=&quot;fold&quot;, ylab = &quot;%&quot;)
points(cv.precisions * 100, pch=19, type=&quot;b&quot;, col=&quot;blue&quot;)
points(cv.accuracies * 100, pch=19, type=&quot;b&quot;, col=&quot;red&quot;)
legend(&quot;bottomright&quot;, c(&quot;Recall&quot;, &quot;Precision&quot;, &quot;Accuracy&quot;), col=c(&quot;black&quot;, &quot;blue&quot;, &quot;red&quot;), lty=1)
</code></pre>

<p><img src="assets/fig/unnamed-chunk-70-1.png" alt="plot of chunk unnamed-chunk-70"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Feature selection with a regression model (1/3)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">require(leaps)

# Prepare data frame
tmp.train.df &lt;- as.data.frame(d.train)
tmp.train.df$Class &lt;- as.numeric(cl.train==&quot;approval&quot;)

# We can specify the linear model as a string
formel &lt;- &quot;Class ~ .&quot;

# Apply forward selection on the attributes
subsets.fit &lt;- regsubsets(as.formula(formel), data=tmp.train.df, method=&quot;forward&quot;)
</code></pre>

<pre><code>## Reordering variables and trying again:
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Feature selection with a regression model (2/3)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r">fit.summary &lt;- summary(subsets.fit)

# Note: &quot;Mallow&#39;s Cp is a measure for a model&#39;s performance, taking into account its complexity&quot;
plot(subsets.fit, scale=&quot;Cp&quot;)
</code></pre>

<p><img src="assets/fig/unnamed-chunk-72-1.png" alt="plot of chunk unnamed-chunk-72"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h1>Feature selection with a regression model (3/3)</h1>
  </hgroup>
  <article data-timings="">
    <pre><code class="r"># Make a plot of model complexity&#39; vs. Mallow&#39;s Cp
# Note: The lower, the better
plot(fit.summary$cp, type=&quot;b&quot;, main=&quot;Mallow&#39;s CP&quot;, xlab=&quot;#Features&quot;, ylab=&quot;Mallow&#39;s Cp&quot;, xlim=c(1,(ncol(tmp.train.df)-1)))
</code></pre>

<p><img src="assets/fig/unnamed-chunk-73-1.png" alt="plot of chunk unnamed-chunk-73"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="class" id="id" style="background:;">
  <hgroup>
    <h2>Summary</h2>
  </hgroup>
  <article data-timings="">
    <p><br/></p>

<ul>
<li>Addressed the core parts of data analysis

<ul>
<li>Data preparation</li>
<li>Data modelling</li>
<li>Data visualization</li>
<li>Model evaluation</li>
</ul></li>
<li>Remember: 

<ul>
<li>Data analysis is an iterative process (CRISP)</li>
<li>Each step will give you insights for the next one</li>
</ul></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>
  <div class="pagination pagination-small" id='io2012-ptoc' style="display:none;">
    <ul>
      <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=1 title='A live demo'>
         1
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=2 title='Analysis goals'>
         2
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=3 title='Methods'>
         3
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=4 title='Introduction'>
         4
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=5 title='An overview of data graphics in R'>
         5
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=6 title='Creating a data toy example (1/2)'>
         6
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=7 title='Creating a data toy example (2/2)'>
         7
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=8 title='Example of a basic plot'>
         8
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=9 title='A simple <code>lattice</code> example'>
         9
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=10 title='A simple <code>ggplot2</code> example'>
         10
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=11 title='Other <code>ggplot2</code> examples (1/2)'>
         11
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=12 title='Other <code>ggplot2</code> examples (2/2)'>
         12
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=13 title='Note on <code>ggplot2</code>'>
         13
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=14 title='Data Analysis - Part I'>
         14
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=15 title='Loading the data'>
         15
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=16 title='An initial inspection of the data'>
         16
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=17 title='Treatment of missing values (1/2)'>
         17
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=18 title='Treatment of missing values (2/2)'>
         18
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=19 title='Inspecting a subset of the data'>
         19
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=20 title='Replacements of symbolic true/false values (1/2)'>
         20
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=21 title='Replacements of symbolic true/false values (2/2)'>
         21
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=22 title='Creating dummies for categorical variables (1/3)'>
         22
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=23 title='Creating dummies for categorical variables (2/3)'>
         23
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=24 title='Creating dummies for categorical variables (3/3)'>
         24
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=25 title='Export data to csv for inspection in an external editor'>
         25
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=26 title='Data Analysis - Part II'>
         26
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=27 title='Count non-zero entries (1/2)'>
         27
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=28 title='Count non-zero entries (2/2)'>
         28
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=29 title='Determining discriminative attributes (1/3)'>
         29
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=30 title='Determining discriminative attributes (2/3)'>
         30
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=31 title='Determining discriminative attributes (3/3)'>
         31
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=32 title='Selecting discriminative attributes by correlations'>
         32
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=33 title='Visualizing with a scatterplot matrix (1/4)'>
         33
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=34 title='Visualizing with a scatterplot matrix (2/4)'>
         34
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=35 title='Visualizing with a scatterplot matrix (3/4)'>
         35
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=36 title='Visualizing with a scatterplot matrix (4/4)'>
         36
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=37 title='Heatmap visualization of pairwise correlations (1/3)'>
         37
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=38 title='Heatmap visualization of pairwise correlations (2/3)'>
         38
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=39 title='Heatmap visualization of pairwise correlations (3/3)'>
         39
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=40 title='Hint: Working with re-usable code snippets'>
         40
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=41 title='Data Analysis - Part III'>
         41
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=42 title='Pre-filtering of attributes'>
         42
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=43 title='Compute a PCA'>
         43
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=44 title='Scatterplot matrix of a PCA (1/2)'>
         44
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=45 title='Scatterplot matrix of a PCA (2/2)'>
         45
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=46 title='Computing kmeans-clusters (1/4)'>
         46
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=47 title='Computing kmeans-clusters (2/4)'>
         47
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=48 title='Computing kmeans-clusters (3/4)'>
         48
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=49 title='Computing kmeans-clusters (4/4)'>
         49
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=50 title='Hierarchical clustering (1/2)'>
         50
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=51 title='Hierarchical clustering (2/2)'>
         51
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=52 title='Learning a decision tree model (1/5)'>
         52
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=53 title='Learning a decision tree model (2/5)'>
         53
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=54 title='Learning a decision tree model (3/5)'>
         54
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=55 title='Plotting the decision tree model (4/5)'>
         55
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=56 title='Learning a decision tree model (5/5)'>
         56
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=57 title='Learning a linear model to classify the data (1/3)'>
         57
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=58 title='Learning a linear model to classify the data (2/3)'>
         58
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=59 title='Learning a linear model to classify the data (3/3)'>
         59
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=60 title='Learning with a SVM (1/3)'>
         60
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=61 title='Learning with a SVM (2/3)'>
         61
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=62 title='Learning with a SVM (3/3)'>
         62
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=63 title='Definitions of performance measures'>
         63
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=64 title='Doing k-fold cross-validation for a SVM (1/3)'>
         64
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=65 title='Doing k-fold cross-validation for a SVM (2/3)'>
         65
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=66 title='Doing k-fold cross-validation for a SVM (3/3)'>
         66
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=67 title='Feature selection with a regression model (1/3)'>
         67
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=68 title='Feature selection with a regression model (2/3)'>
         68
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=69 title='Feature selection with a regression model (3/3)'>
         69
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=70 title='Summary'>
         70
      </a>
    </li>
  </ul>
  </div>  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
  <!-- Load Javascripts for Widgets -->
  
  <!-- LOAD HIGHLIGHTER JS FILES -->
  <script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <!-- DONE LOADING HIGHLIGHTER JS FILES -->
   
  </html>